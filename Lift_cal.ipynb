{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the models and brands mapping\n",
    "mapping_df = pd.read_csv('car_models_and_brands.csv')\n",
    "\n",
    "# Load the data from Data Scrapper Code\n",
    "data_df = pd.read_csv('Edmunds_entryluxcar.csv')\n",
    "\n",
    "# Create a dictionary for mapping models to brands\n",
    "model_to_brand = {}\n",
    "for _, row in mapping_df.iterrows():\n",
    "    brand = row['Brand']\n",
    "    models = row['Model'].split('|')\n",
    "    for model in models:\n",
    "        model_to_brand[model] = brand\n",
    "\n",
    "model_to_brand['s4'] = 'audi'\n",
    "model_to_brand['tlx'] = 'acura'\n",
    "model_to_brand['awd'] = 'cooper'\n",
    "model_to_brand['daytona'] = 'dodge'\n",
    "model_to_brand['wrangler'] = 'jeep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m6user</td>\n",
       "      <td>June 2013</td>\n",
       "      <td>That's why I said given the same scenario as w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fedlawman</td>\n",
       "      <td>June 2013</td>\n",
       "      <td>Semantics, really, and I do see your point, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m6user</td>\n",
       "      <td>June 2013</td>\n",
       "      <td>No, i think we agree in general and that's pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fedlawman</td>\n",
       "      <td>June 2013</td>\n",
       "      <td>So this begs the question, before the automobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dino001</td>\n",
       "      <td>June 2013</td>\n",
       "      <td>I agree with your previous statement. Many peo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User_ID       Date                                            Comment\n",
       "0     m6user  June 2013  That's why I said given the same scenario as w...\n",
       "1  fedlawman  June 2013  Semantics, really, and I do see your point, bu...\n",
       "2     m6user  June 2013  No, i think we agree in general and that's pre...\n",
       "3  fedlawman  June 2013  So this begs the question, before the automobi...\n",
       "4    dino001  June 2013  I agree with your previous statement. Many peo..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Extract the comment column\n",
    "comments = data_df[data_df['Comment'].apply(lambda x: isinstance(x, str))]['Comment']\n",
    "\n",
    "# Tokenize and preprocess the comments (remove punctuation and convert to lowercase)\n",
    "def preprocesstext(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())  # Tokenize and convert to lowercase\n",
    "    return list(set(words))\n",
    "\n",
    "# Tokenize and preprocess the comments\n",
    "all_words = []\n",
    "for comment in comments:\n",
    "    words = preprocesstext(comment)\n",
    "    all_words.extend(words)\n",
    "\n",
    "# Calculate word frequencies\n",
    "word_frequencies = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the                  5123\n",
      "a                    4600\n",
      "to                   4214\n",
      "and                  4089\n",
      "i                    4020\n",
      "                     ... \n",
      "xfs                     1\n",
      "supportadjustment       1\n",
      "bonded                  1\n",
      "botched                 1\n",
      "displayexceptthe        1\n",
      "Length: 23755, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK B: Word frequency table after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/milindbhatia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords (you only need to do this once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Extract the comment column\n",
    "comments = data_df[data_df['Comment'].apply(lambda x: isinstance(x, str))]['Comment']\n",
    "\n",
    "# Get the NLTK English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize and preprocess the comments (remove punctuation, convert to lowercase, and remove stop words)\n",
    "def preprocesstext(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())  # Tokenize and convert to lowercase\n",
    "    nswords = [word for word in words if word not in stop_words]\n",
    "    nswords = [model_to_brand.get(word, word) for word in nswords]\n",
    "    return list(set(nswords))\n",
    "\n",
    "# Tokenize and preprocess the comments, removing stop words\n",
    "words_nostop = []\n",
    "for comment in comments:\n",
    "    words = preprocesstext(comment)\n",
    "    words_nostop.extend(words)\n",
    "\n",
    "# Calculate word frequencies\n",
    "words_nostop_freq = pd.Series(words_nostop).value_counts()\n",
    "\n",
    "wnf_df = pd.DataFrame(words_nostop_freq)\n",
    "wnf_df = wnf_df.reset_index()\n",
    "wnf_df = wnf_df.rename(columns={'index': 'words', 0: 'frequency'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         words  frequency\n",
      "2          bmw       1882\n",
      "7         audi       1521\n",
      "8        acura       1493\n",
      "10      cooper       1404\n",
      "11       honda       1321\n",
      "46  volkswagen        649\n",
      "50       dodge        634\n",
      "51        jeep        633\n",
      "63      subaru        560\n",
      "67      toyota        547\n"
     ]
    }
   ],
   "source": [
    "wnf_df.iloc[61:80,:]\n",
    "\n",
    "top_10_brand_ls = ['bmw','audi','acura','honda','cooper','volkswagen','dodge','subaru','jeep','toyota']\n",
    "\n",
    "top_10_df = wnf_df[wnf_df['words'].isin(top_10_brand_ls)]\n",
    "top_10_df = top_10_df.rename(columns={0: 'frequency'})\n",
    "\n",
    "print(top_10_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK C: LIFT Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = pd.DataFrame(comments)\n",
    "token_df['Tokenized_Message'] = token_df['Comment'].map(preprocesstext)\n",
    "\n",
    "def replace_words_in_list(word_list, replacements):\n",
    "    ls = [replacements.get(word, word) for word in word_list]\n",
    "    return list(set(ls))\n",
    "\n",
    "token_df['Mapped_words'] = token_df['Tokenized_Message'].apply(lambda x: replace_words_in_list(x, model_to_brand))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_distance = 7\n",
    "\n",
    "def distance_thresh(words_list, word1, word2, max_distance):\n",
    "    indices_word1 = [i for i, word in enumerate(words_list) if word == word1]\n",
    "    indices_word2 = [i for i, word in enumerate(words_list) if word == word2]\n",
    "    for idx1 in indices_word1:\n",
    "        for idx2 in indices_word2:\n",
    "            if abs(idx1 - idx2) <= max_distance:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def lift_analysis(data,word_A,word_B,max_distance):\n",
    "    if (word_A == word_B):\n",
    "        return '-'\n",
    "    else:\n",
    "        N = data.shape[0]\n",
    "        N_A = sum(1 for review in data if word_A in review)\n",
    "        N_B = sum(1 for review in data if word_B in review)\n",
    "        N_A_and_B = sum(1 for review in data if distance_thresh(review, word_A, word_B, max_distance) and word_A in review and word_B in review)\n",
    "    \n",
    "        lift = (N * N_A_and_B) / (N_A * N_B)\n",
    "\n",
    "        return np.round(lift,4)\n",
    "\n",
    "df_lift = []\n",
    "\n",
    "for index, brand1 in top_10_df.iterrows():\n",
    "    for index,brand2 in top_10_df.iterrows():\n",
    "        df_lift.append(lift_analysis(token_df['Mapped_words'],brand1['words'],brand2['words'],word_distance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmw</th>\n",
       "      <th>audi</th>\n",
       "      <th>acura</th>\n",
       "      <th>cooper</th>\n",
       "      <th>honda</th>\n",
       "      <th>volkswagen</th>\n",
       "      <th>dodge</th>\n",
       "      <th>jeep</th>\n",
       "      <th>subaru</th>\n",
       "      <th>toyota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>-</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.2993</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.3398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audi</th>\n",
       "      <td>0.0822</td>\n",
       "      <td>-</td>\n",
       "      <td>0.4064</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.1493</td>\n",
       "      <td>2.3019</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acura</th>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.4064</td>\n",
       "      <td>-</td>\n",
       "      <td>0.518</td>\n",
       "      <td>1.7892</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooper</th>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>0.518</td>\n",
       "      <td>-</td>\n",
       "      <td>1.2489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1113</td>\n",
       "      <td>1.2149</td>\n",
       "      <td>0.5754</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honda</th>\n",
       "      <td>0.034</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>1.7892</td>\n",
       "      <td>1.2489</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.3385</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.2504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volkswagen</th>\n",
       "      <td>0.2993</td>\n",
       "      <td>0.1493</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>-</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2596</td>\n",
       "      <td>0.8304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dodge</th>\n",
       "      <td>0.0708</td>\n",
       "      <td>2.3019</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>1.1113</td>\n",
       "      <td>0.3385</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.0348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeep</th>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>1.2149</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>-</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subaru</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.5754</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.2596</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toyota</th>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>0.8304</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bmw    audi   acura  cooper   honda volkswagen   dodge    jeep  \\\n",
       "bmw              -  0.0822  0.1095  0.0251   0.034     0.2993  0.0708  0.0051   \n",
       "audi        0.0822       -  0.4064  0.3644  0.5434     0.1493  2.3019  0.0752   \n",
       "acura       0.1095  0.4064       -   0.518  1.7892     0.1582  0.1338  0.0064   \n",
       "cooper      0.0251  0.3644   0.518       -  1.2489        0.0  1.1113  1.2149   \n",
       "honda        0.034  0.5434  1.7892  1.2489       -     0.0206  0.3385  0.3751   \n",
       "volkswagen  0.2993  0.1493  0.1582     0.0  0.0206          -  0.2149     0.0   \n",
       "dodge       0.0708  2.3019  0.1338  1.1113  0.3385     0.2149       -  0.0451   \n",
       "jeep        0.0051  0.0752  0.0064  1.2149  0.3751        0.0  0.0451       -   \n",
       "subaru       0.063  0.0567  0.6421  0.5754  0.0734     0.2596  0.1019   0.017   \n",
       "toyota      0.3398  0.0145  0.0812   0.322  0.2504     0.8304  0.0348  0.1742   \n",
       "\n",
       "            subaru  toyota  \n",
       "bmw          0.063  0.3398  \n",
       "audi        0.0567  0.0145  \n",
       "acura       0.6421  0.0812  \n",
       "cooper      0.5754   0.322  \n",
       "honda       0.0734  0.2504  \n",
       "volkswagen  0.2596  0.8304  \n",
       "dodge       0.1019  0.0348  \n",
       "jeep         0.017  0.1742  \n",
       "subaru           -  0.0591  \n",
       "toyota      0.0591       -  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "lift_np = np.reshape(df_lift,(10,10))\n",
    "lift_df = pd.DataFrame(data= lift_np)\n",
    "for i in range(10):\n",
    "    lift_df = lift_df.rename(columns = {i: top_10_df.iloc[i, 0]})\n",
    "    lift_df = lift_df.rename(index = {i: top_10_df.iloc[i, 0]})\n",
    "lift_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BELOW LINES TO BE REMOVED - ONLY FOR DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_analysis(token_df['Mapped_words'],'bmw','honda',word_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "word_A = 'bmw'\n",
    "word_B = 'honda'\n",
    "N = token_df['Mapped_words'].shape[0]\n",
    "N_A = sum(1 for review in token_df['Mapped_words'] if word_A in review)\n",
    "N_B = sum(1 for review in token_df['Mapped_words'] if word_B in review)    \n",
    "N_A_and_B = sum(1 for review in token_df['Mapped_words'] if distance_thresh(review, word_A, word_B, 7) and word_A in review and word_B in review)\n",
    "lift = (N * N_A_and_B) / (N_A * N_B)\n",
    "print(N_A_and_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['read', 'cs', 'interesting', 'sells', 'sh', 'xle', 'link', 'jeep', '4xe', 'mb', '2022', 'type', 'didnt', '3s', 'realize', 'cooper', 'thanks', 'honda', 'many', 'sween', 'sahara', 'bmw', 'toyota', '2001']\n",
      "['wheel', 'going', 'sh', 'xle', 'next', 'jeep', '4xe', 'lease', '2022', 'type', 'want', 'leasing', 'purchase', 'cooper', 'honda', 'hamster', 'sahara', 'vehicle', 'im', 'bmw', 'toyota', '2001']\n",
      "['heard', 'driven', 'fedthanks', 'yet', 'hybrid', '2023', 'matter', 'driving', 'first', 'ive', 'event', 'person', 'drive', 'one', 'road', 'fact', 'honda', 'touring', '320i', 'havent', 'youre', 'couple', 'saw', 'bmw', 'test', 'seen']\n",
      "['biggest', 'doesnt', 'backup', 'camera', 'sh', 'xle', 'jeep', '4xe', '328xi', 'feature', '2022', 'type', 'cooper', 'honda', 'acura', 'miss', 'sahara', 'bmw', 'toyota', '2001']\n",
      "['sahara', 'honda', 'jeep', '4xe', 'need', 'another', '2022', 'bmw', 'type', 'sh', 'xle', 'toyota', '50000', 'cooper', '2001']\n",
      "['honda', '2023', 'update', 'check', 'touring', 'bmw', 'fnthanks', 'ill', 'naias', 'hybrid', 'pics']\n",
      "['bms', 'add', 'gets', '2001', '1', 'sh', 'xle', 'flightnurse', 'jeep', '4xe', '2022', 'stage', 'type', 'cooper', 'honda', 'boost', 'advantage', 'warranty', '3', 'sahara', 'psi', 'bmw', 'toyota', 'voided']\n",
      "['coming', 'ans', 'selling', 'going', 'sh', 'xle', 'think', 'value', 'low', 'jeep', '4xe', 'cpo', 'lease', '2022', 'type', 'cooper', 'start', 'honda', '320i', 'sahara', '20k', 'tremendous', 'bmw', 'mid', 'toyota', '2001']\n",
      "['break', '2018', 'might', 'nickname', 'mine', '4ws', 'used', '24', 'high', 'cooper', 'honda', 'miles', 'wifes', 'acura', 'ex', 'tech', 'bmw', 'fit', 'wallet', 'people']\n",
      "['tight', 'far', '220870', '222151', '2018', '1', 'mine', 'luxury', '4ws', 'mb', 'top', '223348', 'lexus', '24', '2', 'cooper', 'year', 'honda', 'wifes', 'acura', 'ex', 'tech', 'race', '3', 'bmw']\n",
      "['noise', 'thrilled', 'also', 'accleration', 'sh', 'xle', 'gotten', 'dino001', 'jeep', '4xe', 'wind', 'sticker', 'used', 'know', 'bank', 'compared', 'ive', 'type', 'price', '2022', 'vault', 'mileage', 'engines', 'cooper', 'much', 'seem', 'honda', 'lol', 'considerable', 'theres', 'sahara', '20k', 'im', 'bmw', 'output', '60', 'amount', 'toyota', 'e90', '2001']\n",
      "['tonight', 'coupe', 'sh', 'xle', 'flightnurse', 'jeep', '4xe', 'grand', '2022', 'type', 'cooper', 'honda', 'b6', 'saw', 'sahara', 'home', 'way', 'bmw', 'toyota', '2001']\n",
      "['need', 'judge', 'must', 'store', 'previous', 'least', 'hybrid', '2023', 'michaell', 'one', 'lawyer', 'honda', 'show', 'genius', 'touring', 'qualifications', 'quotes', 'bmw', 'said']\n",
      "['2018', 'comparison', 'week', 'better', 'mine', 'liked', '4ws', 'httpswwwyoutubecomwatchvgeblwnyww8u', '24', 'cooper', 'audi', 'honda', 'wifes', 'acura', 'ex', 'tech', 'motor', 'bmw', 'even']\n"
     ]
    }
   ],
   "source": [
    "count_a  = 0\n",
    "word_A = 'bmw'\n",
    "word_B = 'honda'\n",
    "for review in token_df['Mapped_words']:\n",
    "    if distance_thresh(review, word_A, word_B, 7) and word_A in review and word_B in review:\n",
    "        print(review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
